\documentclass[11pt]{article}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{mathtools}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[polish]{babel}
\usepackage{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{cancel}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{float}

% - A4 Desktop page -
\geometry{
    a4paper,
    left=25mm,
    right=25mm,
    top=25mm,
    bottom=25mm,
}

\linespread{1.25}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
}

% Math spacing
\setlength{\abovedisplayskip}{10pt}
\setlength{\belowdisplayskip}{10pt}
\setlength{\abovedisplayshortskip}{5pt}
\setlength{\belowdisplayshortskip}{5pt}

% Section formatting
\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries}{\thesection}{0.5em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{0.5em}{}
\titleformat{\subsubsection}{\normalsize\itshape}{\thesubsubsection}{0.5em}{}
\titlespacing*{\section}{0pt}{18pt}{8pt}
\titlespacing*{\subsection}{0pt}{14pt}{6pt}
\titlespacing*{\subsubsection}{0pt}{10pt}{4pt}

\usepackage[font=small, labelfont=bf]{caption}
\usepackage{enumitem}
\setlist{itemsep=2pt, leftmargin=*, labelindent=0pt}

% Allow generous line-breaking in math
\allowdisplaybreaks

% Prevent overfull hboxes
\setlength{\emergencystretch}{1em}

\begin{document}

\begin{center}
    {\LARGE\bfseries Macierz Stereoskopowej Percepcji MSP}\\[8pt]
    {\large Stereo Perception Matrix - od paralaksy do przestrzeni postrzeganej}
\end{center}

\section{Konfiguracja}

Użytkownik patrzy na lentykularny wyświetlacz 3D. Układ współrzędnych ma początek w~środku ekranu:
\begin{itemize}
    \item oś $x$ -- pozioma, w prawo (z~perspektywy użytkownika)
    \item oś $y$ -- pionowa, do góry
    \item oś $z$ -- w stronę użytkownika
\end{itemize}

Głowa użytkownika w punkcie $(x_u, y_u, z_u)$, rozstaw źrenic (IPD) wynosi $d$. Pozycje oczu:
\begin{align}
    \text{Lewe oko:} \; & \Big(x_u - \tfrac{d}{2},\; y_u,\; z_u\Big) \\[2pt]
    \text{Prawe oko:} \; & \Big(x_u + \tfrac{d}{2},\; y_u,\; z_u\Big)
\end{align}

Lewe oko widzi punkt na ekranie w~pozycji $(x_{dl}, y_d, 0)$, prawe oko widzi ten sam punkt w~pozycji $(x_{dr}, y_d, 0)$. Współrzędne $y$ są równe ($y_d$), bo kamery mają tę samą wysokość i~orientację.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8, >=latex]
    % Ekran
    \fill[blue!8] (-3.8, 0) rectangle (3.8, 0.12);
    \draw[thick, blue!60] (-3.8, 0) -- (3.8, 0);
    \node[below, blue!60, font=\tiny] at (0.1, 0.08) {ekran ($z = 0$)};

    % Punkty na ekranie
    \fill[red!70!black] (1.5, 0) circle (2pt);
    \node[above, red!70!black, font=\tiny] at (2.5, 0.15) {$(x_{dl}, y_d, 0)$};

    \fill[green!50!black] (-0.4, 0) circle (2pt);
    \node[above, green!50!black, font=\tiny] at (-1.5, 0.15) {$(x_{dr}, y_d, 0)$};

    % Oczy
    \fill[red!70!black] (-1.2, 4.2) circle (3pt);
    \node[above left, font=\tiny] at (-1.2, 4.2) {Lewe oko};
    \node[below left, font=\tiny] at (-1.2, 4.05) {{\scriptsize$(x_u\!-\!\frac{d}{2}, y_u, z_u)$}};

    \fill[green!50!black] (1.2, 4.2) circle (3pt);
    \node[above right, font=\tiny] at (1.2, 4.2) {Prawe oko};
    \node[below right, font=\tiny] at (1.2, 4.05) {{\scriptsize$(x_u\!+\!\frac{d}{2}, y_u, z_u)$}};

    \fill[gray] (0, 4.2) circle (1.5pt);
    \node[above, gray, font=\tiny] at (0, 4.25) {$(x_u, y_u, z_u)$};
    \draw[gray, dashed, thin] (-1.2, 4.2) -- (1.2, 4.2);
    \draw[gray, |<->|, thin] (-1.2, 5) -- node[above, font=\tiny] {$d$} (1.2, 5);

    % Promienie
    \draw[red!70!black, thick, ->] (-1.2, 4.2) -- (1.5, 0);

    \draw[green!50!black, thick, ->] (1.2, 4.2) -- (-0.4, 0);

    % Punkt przecięcia
    \fill[orange!80!black] (0.3, 1.8) circle (3pt);
    \node[right, orange!80!black, font=\tiny] at (0.45, 1.8) {$(x_t, y_t, z_t)$};
    \node[right, orange!80!black, font=\tiny] at (0.55, 1.4) {punkt 3D};

    % Wektory
    \node[red!70!black, font=\tiny, rotate=-57] at (-0.4, 2.5) {$\vec{v}_L$};
    \node[green!50!black, font=\tiny, rotate=68] at (0.7, 2.5) {$\vec{v}_R$};

    % Osie
    \draw[gray, ->, thin] (0, -0.4) -- (0, 6.5);
    \node[gray, font=\tiny] at (0.2, 6.5) {$z$};
    \draw[gray, ->, thin] (-5, -0.4) -- (5, -0.4);
    \node[gray, font=\tiny] at (3.8, -0.65) {$x$};
\end{tikzpicture}
\caption{Rzut od dołu. Schemat przecięcia promieni. Czerwony - lewy promień, zielony - prawy. Pomarańczowy - postrzegany punkt 3D. Przypadek $x_{dl} > x_{dr}$ - obiekt przed ekranem (paralaksa ujemna).}
\label{fig:ray_intersection}
\end{figure}

\section{Wektory kierunkowe}

Promień świetlny to prosta w~przestrzeni 3D. Aby jednoznacznie opisać prostą, potrzebujemy:
\begin{enumerate}
    \item \textbf{punktu}, przez który prosta przechodzi,
    \item \textbf{wektora kierunkowego}, który wskazuje kierunek.
\end{enumerate}

Każdy promień przechodzi przez dwa znane punkty: punkt na ekranie i~odpowiednie oko. Wektor kierunkowy:
\begin{equation}
    \vec{v} = B - A
\end{equation}

\subsection{Lewy promień}

Lewy promień przechodzi przez:
\begin{itemize}
    \item punkt na ekranie: $A_L = (x_{dl},\; y_d,\; 0)$
    \item pozycję lewego oka: $B_L = (x_u - \tfrac{d}{2},\; y_u,\; z_u)$
\end{itemize}

Wektor kierunkowy - pozycja oka minus punkt na ekranie:
\begin{equation}
    \vec{v}_L = B_L - A_L
\end{equation}

Odejmujemy składowa po składowej:
\begin{equation}
    \vec{v}_L = \Big(x_u - x_{dl} - \tfrac{d}{2},\;\; y_u - y_d,\;\; z_u\Big)
\end{equation}

\subsection{Prawy promień}

Prawy promień przechodzi przez:
\begin{itemize}
    \item punkt na ekranie: $A_R = (x_{dr},\; y_d,\; 0)$
    \item prawe oko: $B_R = (x_u + \tfrac{d}{2},\; y_u,\; z_u)$
\end{itemize}

Analogicznie:
\begin{equation}
    \vec{v}_R = \Big(x_u - x_{dr} + \tfrac{d}{2},\;\; y_u - y_d,\;\; z_u\Big)
\end{equation}

\subsection{Dlaczego akurat ta kolejność?}

Kierunek wektora ($B - A$ vs $A - B$) jest kwestią konwencji. Wybieramy kierunek od ekranu w~stronę oka (rosnące $z$), ponieważ w~zapisie parametrycznym startujemy z~pozycji oka ($\alpha = 0$) i~chcemy, aby $\alpha = -1$ odpowiadało punktowi na ekranie:
\begin{equation}
    P(\alpha) = \underbrace{B}_{\text{oko}} + \alpha \cdot \underbrace{(B - A)}_{\vec{v}}
    \;\Rightarrow\;
    P(-1) = A
\end{equation}

\section{Zapis parametryczny obu promieni}

Punkt na lewym promieniu dla parametru $\alpha_1$:
\begin{equation}
    P_L(\alpha_1) = \begin{pmatrix} x_u - \frac{d}{2} \\ y_u \\ z_u \end{pmatrix}
    + \alpha_1 \begin{pmatrix} x_u - x_{dl} - \frac{d}{2} \\ y_u - y_d \\ z_u \end{pmatrix}
\end{equation}

Punkt na prawym promieniu dla parametru $\alpha_2$ - rozpiszemy szczegółowo, jak powstaje.

\medskip
\textbf{Dane wejściowe} - dwa punkty prawego promienia:
\begin{align}
    A_R &= (x_{dr},\; y_d,\; 0) & &\text{punkt na ekranie} \\
    B_R &= \Big(x_u + \tfrac{d}{2},\; y_u,\; z_u\Big) & &\text{prawe oko}
\end{align}

\textbf{Krok 1: wektor kierunkowy} $\vec{v}_R = B_R - A_R$, składowa po składowej:
\begin{align}
    v_x &= \Big(x_u + \frac{d}{2}\Big) - x_{dr} = x_u - x_{dr} + \frac{d}{2} \\[3pt]
    v_y &= y_u - y_d \\[3pt]
    v_z &= z_u - 0 = z_u
\end{align}

\textbf{Krok 2: podstawienie} do wzoru ogólnego $P(\alpha) = B + \alpha \cdot \vec{v}$:
\begin{equation}
    P_R(\alpha_2) = \underbrace{\begin{pmatrix} x_u + \frac{d}{2} \\[3pt] y_u \\[3pt] z_u \end{pmatrix}}_{B_R} + \;\alpha_2\; \underbrace{\begin{pmatrix} x_u - x_{dr} + \frac{d}{2} \\[3pt] y_u - y_d \\[3pt] z_u \end{pmatrix}}_{\vec{v}_R}
\end{equation}

\textbf{Sprawdzenie} - czy $\alpha_2 = -1$ daje punkt na ekranie?

\begin{itemize}
    \item $x$: $\Big(x_u + \frac{d}{2}\Big) - \Big(x_u - x_{dr} + \frac{d}{2}\Big) = \cancel{x_u} + \cancel{\frac{d}{2}} - \cancel{x_u} + x_{dr} - \cancel{\frac{d}{2}} = x_{dr}$ \;
    \item $y$: $y_u - (y_u - y_d) = \cancel{y_u} - \cancel{y_u} + y_d = y_d$ \;
    \item $z$: $z_u - z_u = 0$ \;
\end{itemize}

Wynik: $(x_{dr}, y_d, 0) = A_R$ - $\alpha_2 = -1$ rzeczywiście daje punkt na ekranie.

\medskip
Uwaga: zapis parametryczny zaczyna się w~pozycji oka ($\alpha = 0$), a~przy $\alpha = -1$ promień dociera do punktu na ekranie.

\section{Układ równań}

W~punkcie przecięcia oba promienie muszą dawać ten sam punkt w~przestrzeni:
\begin{equation}
    P_L(\alpha_1) = P_R(\alpha_2)
\end{equation}

Rozpiszmy obie strony. Lewa strona (z~równania na $P_L$):
\begin{equation}
    P_L(\alpha_1) = \begin{pmatrix} x_u - \frac{d}{2} \\ y_u \\ z_u \end{pmatrix}
    + \alpha_1 \begin{pmatrix} x_u - x_{dl} - \frac{d}{2} \\ y_u - y_d \\ z_u \end{pmatrix}
\end{equation}

Wykonujemy mnożenie $\alpha_1 \cdot \vec{v}_L$ i~dodajemy do $B_L$, składowa po składowej:
\begin{equation}
    P_L(\alpha_1) = \begin{pmatrix}
        \big(x_u - \frac{d}{2}\big) + \alpha_1 \big(x_u - x_{dl} - \frac{d}{2}\big) \\[6pt]
        y_u + \alpha_1 (y_u - y_d) \\[4pt]
        z_u + \alpha_1 \, z_u
    \end{pmatrix}
\end{equation}

Prawa strona (z~równania na $P_R$):
\begin{equation}
    P_R(\alpha_2) = \begin{pmatrix} x_u + \frac{d}{2} \\ y_u \\ z_u \end{pmatrix}
    + \alpha_2 \begin{pmatrix} x_u - x_{dr} + \frac{d}{2} \\ y_u - y_d \\ z_u \end{pmatrix}
\end{equation}

Analogicznie rozwijamy:
\begin{equation}
    P_R(\alpha_2) = \begin{pmatrix}
        \big(x_u + \frac{d}{2}\big) + \alpha_2 \big(x_u - x_{dr} + \frac{d}{2}\big) \\[6pt]
        y_u + \alpha_2 (y_u - y_d) \\[4pt]
        z_u + \alpha_2 \, z_u
    \end{pmatrix}
\end{equation}

Teraz przyrównujemy odpowiadające sobie składowe - jeśli dwa wektory są równe, to każda ich składowa musi być równa osobno:

\medskip
\textbf{Składowa $x$} (pierwszy wiersz = pierwszy wiersz):
\begin{equation}
    \big(x_u - \tfrac{d}{2}\big) + \alpha_1 \big(x_u - x_{dl} - \tfrac{d}{2}\big) = \big(x_u + \tfrac{d}{2}\big) + \alpha_2 \big(x_u - x_{dr} + \tfrac{d}{2}\big)
\end{equation}

\textbf{Składowa $y$} (drugi wiersz = drugi wiersz):
\begin{equation}
    y_u + \alpha_1 (y_u - y_d) = y_u + \alpha_2 (y_u - y_d)
\end{equation}

\textbf{Składowa $z$} (trzeci wiersz = trzeci wiersz):
\begin{equation}
    z_u + \alpha_1 \, z_u = z_u + \alpha_2 \, z_u
\end{equation}

\medskip
Te trzy równania tworzą układ - dwie niewiadome ($\alpha_1$, $\alpha_2$), trzy równania (układ nadokreślony, ale jak pokażemy, jest spójny):

{\small
\begin{equation} \label{eq:system}
    \boxed{
    \begin{cases}
        x_u - \frac{d}{2} + \alpha_1 \big(x_u - x_{dl} - \frac{d}{2}\big) \\
        \quad= x_u + \frac{d}{2} + \alpha_2 \big(x_u - x_{dr} + \frac{d}{2}\big) \\[8pt]
        y_u + \alpha_1 (y_u - y_d) = y_u + \alpha_2 (y_u - y_d) \\[4pt]
        z_u + \alpha_1 z_u = z_u + \alpha_2 z_u
    \end{cases}
    }
\end{equation}
}

\section{Rozwiązanie układu}

\subsection{Krok 1: Z~osi $z$ - $\alpha_1 = \alpha_2$}

Trzecie równanie:
\begin{equation}
    \cancel{z_u} + \alpha_1 z_u = \cancel{z_u} + \alpha_2 z_u
    \;\Rightarrow\;
    \alpha_1 z_u = \alpha_2 z_u
\end{equation}

Ponieważ $z_u \neq 0$ (użytkownik nie siedzi wewnątrz ekranu):
\begin{equation}
    \alpha_1 = \alpha_2
\end{equation}

Równanie dla osi $y$ potwierdza niezależnie:
\begin{equation}
    \cancel{y_u} + \alpha_1(y_u - y_d) = \cancel{y_u} + \alpha_2(y_u - y_d)
    \;\Rightarrow\;
    \alpha_1 = \alpha_2
\end{equation}

(przy $y_u \neq y_d$). Od tego momentu piszemy $\alpha \equiv \alpha_1 = \alpha_2$.

\subsection{Krok 2: Z~osi $x$ wyznaczamy $\alpha$}

Podstawiamy $\alpha_1 = \alpha_2 = \alpha$ do pierwszego równania:
{\small
\begin{equation}
    x_u - \frac{d}{2} + \alpha\big(x_u - x_{dl} - \frac{d}{2}\big) = x_u + \frac{d}{2} + \alpha\big(x_u - x_{dr} + \frac{d}{2}\big)
\end{equation}
}

Skracamy $x_u$ po obu stronach:
{\small
\begin{equation}
    - \frac{d}{2} + \alpha\big(x_u - x_{dl} - \frac{d}{2}\big) = \frac{d}{2} + \alpha\big(x_u - x_{dr} + \frac{d}{2}\big)
\end{equation}
}

Przenosimy:
\begin{equation}
    \alpha\big[\cancel{x_u} - x_{dl} - \frac{d}{2} - \cancel{x_u} + x_{dr} - \frac{d}{2}\big] = d
\end{equation}

\begin{equation}
    \alpha\big(x_{dr} - x_{dl} - d\big) = d
\end{equation}

Zatem:
\begin{equation}
    \boxed{\alpha = \frac{d}{x_{dr} - x_{dl} - d} = -\frac{d}{d + x_{dl} - x_{dr}}}
\end{equation}

\section{Interpretacja fizyczna parametru $\alpha$}

Parametr $\alpha$ określa, jak daleko wzdłuż promienia (względem odległości oko--ekran) leży punkt przecięcia.

\begin{itemize}
    \item W~mianowniku: $d + x_{dl} - x_{dr}$, gdzie:
    \begin{itemize}
        \item $d$ -- rozstaw źrenic (IPD)
        \item $x_{dl} - x_{dr}$ -- \textbf{dysparycja/dysparyczność metryczna} (przesunięcie na ekranie, w~mm)
    \end{itemize}
\end{itemize}

Zbadajmy zachowanie $\alpha$ dla różnych wartości dysparyczności:

\begin{center}
{\small
\begin{tabular}{c c c l}
    \hline
    $x_{dl} - x_{dr}$ & $d + (x_{dl} - x_{dr})$ & $\alpha$ & \textbf{Interpretacja} \\
    \hline
    $> 0$ & $> d$ & $(-1, 0)$ & przed ekranem \\
    $= 0$ & $d$ & $-1$ & \textbf{na ekranie} \\
    $\in (-d, 0)$ & $\in (0, d)$ & $< -1$ & za ekranem \\
    $\to -d$ & $\to 0^+$ & $\to -\infty$ & \textbf{w nieskończoności} \\
    \hline
\end{tabular}
}
\end{center}

Sprawdzenie kluczowych przypadków:
\begin{itemize}
    \item \textbf{Zerowa dysparyczność} ($x_{dl} = x_{dr}$, jedno i drugie oko użytkownika widzi punkt w tym samym miejscu):
    $\alpha = -\frac{d}{d + 0} = -1$ - obiekt na powierzchni ekranu 
    \item \textbf{Dysparyczność $\to -d$} (promienie prawie równoległe, jak patrząc w~dal):
    $\alpha = -\frac{d}{d + (-d)} = -\frac{d}{0^+} \to -\infty$ - obiekt w~nieskończoności 
    \item \textbf{Dysparyczność dodatnia} ($x_{dl} > x_{dr}$, skrzyżowane promienie):
    $\alpha \in (-1, 0)$ - obiekt przed ekranem (paralaksa ujemna) 
\end{itemize}

\medskip
Podsumowując - promień zaczyna w~oku ($\alpha = 0$) i~przechodzi przez ekran przy $\alpha = -1$:
\begin{itemize}
    \item $-1 < \alpha < 0$: obiekt \textbf{przed} ekranem (paralaksa ujemna)
    \item $\alpha = -1$: \textbf{w~płaszczyźnie} ekranu (paralaksa zerowa)
    \item $\alpha < -1$: obiekt \textbf{za} ekranem (paralaksa dodatnia)
    \item $\alpha \to -\infty$: obiekt \textbf{w~nieskończoności}
\end{itemize}

\section{Końcowe współrzędne postrzeganego punktu 3D}
\label{sec:perceived_point}

Podstawiając $\alpha$ do $P_L$ lub $P_R$:

\begin{equation}
    \boxed{
    \begin{pmatrix}
        x_t \\[4pt] y_t \\[4pt] z_t
    \end{pmatrix}
    =
    \begin{pmatrix}
        x_u + \frac{d}{d + x_{dl} - x_{dr}} \big( \frac{x_{dl} + x_{dr}}{2} - x_u \big) \\[8pt]
        y_u + \frac{d}{d + x_{dl} - x_{dr}} \big( y_d - y_u \big) \\[8pt]
        z_u \big( 1 - \frac{d}{d + x_{dl} - x_{dr}} \big)
    \end{pmatrix}
    }
\end{equation}

Jest to 'formuła' (układ równań) zaproponowany przez . \\
\url{https://confluence-eu.sec.samsung.net/spaces/VDIMEX/pages/585405331/Coordinates+of+a+3D+object+in+human+s+perception?preview=/585405331/585410432/3d_object_position.pdf}


gdzie:
\begin{itemize}
    \item $(x_u, y_u, z_u)$ -- pozycja środka między oczami
    \item $d$ -- rozstaw źrenic (IPD)
    \item $x_{dl}, x_{dr}$ -- pozycje na ekranie (L/P)
    \item $y_d$ -- pozycja pionowa na ekranie
\end{itemize}

\subsection*{Kluczowe właściwości}

\begin{enumerate}
    \item Każda współrzędna docelowa zależy tylko od odpowiadającej sobie współrzędnej użytkownika.
    \item Postrzegana głębokość $z_t$ jest proporcjonalna do $z_u$.
    \item Wspólny czynnik $\frac{d}{d + x_{dl} - x_{dr}}$ pojawia się we~wszystkich trzech współrzędnych.
\end{enumerate}

\section{Jedna macierz transformacji: scena 3D $\to$ punkt 3D}
\label{sec:single_matrix}

Dotychczasowe wzory wyrażają postrzegany punkt $(x_t, y_t, z_t)$ w~funkcji współrzędnych ekranowych. Ale te współrzędne same zależą od punktu w~wirtualnej scenie 3D. Cały pipeline:

\begin{center}
\begin{tikzpicture}[>=latex, every node/.style={font=\tiny}]
    \node[draw, inner sep=3pt] (A) at (0, 0) {$(X,Y,Z)$};
    \node[draw, inner sep=3pt] (B) at (3.2, 0) {$(x_n,y_n)$};
    \draw[->, thick] (A) -- node[above] {projekcja} (B);
    \node[above=2pt of A, font=\tiny, gray] {punkt sceny};
    \node[above=2pt of B, font=\tiny, gray] {znormalizowane};
    \node[draw, inner sep=3pt] (C) at (1.6, -1.2) {$(x_d,y_d)$};
    \node[draw, inner sep=3pt] (D) at (5, -1.2) {$(x_t,y_t,z_t)$};
    \draw[->, thick] (B) -- node[right] {skalowanie} (C);
    \draw[->, thick] (C) -- node[above] {paralaksa} (D);
    \node[below=2pt of C, font=\tiny, gray] {mm na ekranie};
    \node[below=2pt of D, font=\tiny, gray] {punkt 3D};
\end{tikzpicture}
\end{center}

\textbf{Cały pipeline = jedna macierz $4\times 4$} we~współrzędnych jednorodnych.

\subsection{Założenia}

\begin{itemize}
    \item Układ \textbf{lewoskrętny} (LH), kamera patrzy wzdłuż $+z$.
    \item Dwie kamery wirtualne o~\textbf{równoległych} osiach optycznych (parallel-axis stereo, bez toe-in), rozstawione o~$D$ (baza stereo), patrzące wzdłuż $+z$.
    \item Lewa kamera w~$(-D/2, 0, 0)$, prawa w~$(D/2, 0, 0)$ w~układzie świata.
    \item \textbf{Symetryczny frustum}: $l = -r$, $b = -t$ (\texttt{PerspectiveFovLH}. Dla uproszczenie obliczeń stosujemy symetryczny frustrum. Docelowo powinien być \textbf{ASYMETRYCZNY!}, co zostało dodatkowo wyprowadzone w następnej części dokumentu. ).
    \item Kąt widzenia pionowy $fovy$, proporcje $ar = w/h$.
    \item Ekran fizyczny: szerokość $w$, wysokość $h$ [mm].
    \item Punkt sceny $(X, Y, Z)$, $Z > 0$ (układ LH).
\end{itemize}

\subsubsection{Skąd wiemy, że frustum jest symetryczny? Babylon.js}

W~silniku \textbf{Babylon.js} (który używamy do renderingu) kamera \texttt{FreeCamera} / \texttt{TargetCamera} tworzy macierz projekcji wywołaniem:

{\small\texttt{Matrix.PerspectiveFovLH(fov, aspect, near, far)}}

\noindent które \textbf{z~definicji} daje symetryczny frustum - kamera patrzy wzdłuż środka prostokąta na near plane, więc:
\begin{equation}
    l = -r, \qquad b = -t
\end{equation}

Parametry dostępne z~API kamery Babylon.js:

\begin{center}
{\scriptsize
\begin{tabular}{l l l}
    \hline
    \textbf{Właściwość JS} & \textbf{Symbol} & \textbf{Opis} \\
    \hline
    \texttt{camera.fov} & $fovy$ & kąt widzenia [rad] \\
    \texttt{camera.fovMode} & - & pionowy (domyślnie) \\
    \texttt{camera.minZ} & $n$ & near plane \\
    \texttt{camera.maxZ} & $f$ & far plane \\
    \texttt{canvas.width/height} & $ar$ & aspect ratio \\
    \hline
\end{tabular}
}
\end{center}

Z tych właściwości obliczamy granice frustum:
\begin{align}
    t &= n \cdot \tan\!\Big(\frac{fovy}{2}\Big), & b &= -t \\[3pt]
    r &= t \cdot ar, & l &= -r
\end{align}


\subsubsection{Pipeline transformacji}

Punkt sceny $(X, Y, Z)$ przechodzi przez następujący łańcuch transformacji, z~których każda jest macierzą $4 \times 4$:

\begin{center}
\begin{tikzpicture}[>=latex, every node/.style={font=\tiny}, node distance=0.4cm]
    \node[draw, inner sep=2pt] (W) {World};
    \node[draw, inner sep=2pt, right=of W] (V) {View};
    \node[draw, inner sep=2pt, right=of V] (C) {Clip};
    \node[draw, inner sep=2pt, right=of C] (N) {NDC};
    \node[draw, inner sep=2pt, right=of N] (S) {Screen};

    \draw[->, thick] (W) -- node[above] {$V$} (V);
    \draw[->, thick] (V) -- node[above] {$P$} (C);
    \draw[->, thick] (C) -- node[above] {$\div w'$} (N);
    \draw[->, thick] (N) -- node[above] {skala} (S);
\end{tikzpicture}
\end{center}


\begin{enumerate}
    \item \textbf{World $\to$ View} (macierz $V$, \texttt{camera.getViewMatrix()}): Przesuwa i~obraca scenę do układu kamery. Dla kamery w~punkcie $(c_x, 0, 0)$ patrzącej wzdłuż $+z$ (LH) jest to translacja o~$(-c_x, 0, 0)$.

    \item \textbf{View $\to$ Clip} (macierz $P$): \textbf{Macierz projekcji perspektywicznej} - w~Babylon.js jest generowana przez statyczną metodę:

    {\small\texttt{Matrix.PerspectiveFovLHToRef(fov, aspect, znear, zfar, result)}}

    \textbf{Źródła}:
    \begin{itemize}
        \item \href{https://doc.babylonjs.com/typedoc/classes/BABYLON.Camera}{Babylon.js Camera API} --- właściwości \texttt{fov}, \texttt{minZ}, \texttt{maxZ}
        \item \href{https://github.com/BabylonJS/Babylon.js/blob/master/packages/dev/core/src/Cameras/camera.ts}{Kod źródłowy camera.ts (GitHub)} --- wewnętrzne wywołanie \texttt{PerspectiveFovLH}
        \item \href{https://doc.babylonjs.com/typedoc/classes/BABYLON.Matrix\#PerspectiveFovLH}{Matrix.PerspectiveFovLH} --- budowa macierzy z~$fov$, $ar$, $n$, $f$
        \item \href{https://doc.babylonjs.com/typedoc/classes/BABYLON.Frustum}{Babylon.js Frustum} --- ekstrakcja 6~płaszczyzn z~macierzy projekcji
    \end{itemize}


    \noindent Metoda ta buduje macierz $4 \times 4$ zapisaną w~tablicy \texttt{result.\_m[0..15]}. Wewnętrznie Babylon.js przechowuje macierze w~porządku \textbf{wierszowym} (row-major), a~mnożenie wektora odbywa się jako $\vec{v} \cdot P$ (wektor-wiersz po lewej). W~notacji matematycznej (kolumnowej, $P \cdot \vec{v}$) odpowiadająca macierz to transpozycja:

    Oznaczając $a \equiv \frac{1}{ar \cdot \tan(fovy/2)}$ i~$b \equiv \frac{1}{\tan(fovy/2)}$:
    
    Parametry te pochodzą z konstrukcji macierzy projekcji perspektywicznej w OpenGL. Wartość $b = \frac{1}{\tan(fovy/2)}$ odpowiada skalowaniu w osi Y, a wartość $a = \frac{1}{ar \cdot \tan(fovy/2)}$ odpowiada skalowaniu w osi X z uwzględnieniem proporcji obrazu. Szczegółowe wyprowadzenie można znaleźć w dokumentacji Song Ho Ahn: \href{https://www.songho.ca/opengl/gl_projectionmatrix.html#fov}{OpenGL Projection Matrix}.
    
    Aby lepiej zrozumieć skąd biorą się te wartości, przyjrzyjmy się kodowi funkcji \texttt{makeFrustum}, która tworzy macierz projekcji na podstawie parametrów frustum:
    
    \begin{verbatim}
Matrix4 makeFrustum(float fovY, float aspectRatio, float front, float back)
{
    const float DEG2RAD = acos(-1.0f) / 180;

    float tangent = tan(fovY/2 * DEG2RAD);    // tangent of half fovY
    float top = front * tangent;              // half height of near plane
    float right = top * aspectRatio;          // half width of near plane

    // params: left, right, bottom, top, near(front), far(back)
    Matrix4 matrix;
    matrix[0]  =  front / right;
    matrix[5]  =  front / top;
    matrix[10] = -(back + front) / (back - front);
    matrix[11] = -1;
    matrix[14] = -(2 * back * front) / (back - front);
    matrix[15] =  0;
    return matrix;
}
    \end{verbatim}
    
    W tej funkcji:
    \begin{itemize}
        \item \texttt{front} odpowiada odległości near plane ($n$)
        \item \texttt{back} odpowiada odległości far plane ($f$)
        \item \texttt{top} to połowa wysokości near plane ($t = n \cdot \tan(fovy/2)$)
        \item \texttt{right} to połowa szerokości near plane ($r = t \cdot ar$)
    \end{itemize}
    
    Zauważmy, że:
    \begin{itemize}
        \item $matrix[0] = \frac{front}{right} = \frac{n}{r} = \frac{n}{t \cdot ar} = \frac{n}{n \cdot \tan(fovy/2) \cdot ar} = \frac{1}{ar \cdot \tan(fovy/2)} = a$
        \item $matrix[5] = \frac{front}{top} = \frac{n}{t} = \frac{n}{n \cdot \tan(fovy/2)} = \frac{1}{\tan(fovy/2)} = b$
    \end{itemize}
    
    W ten sposób widzimy bezpośrednie powiązanie między parametrami $a$ i $b$ a geometrią frustum i kątem widzenia kamery.

    {\small
    \begin{equation} \label{eq:babylon_P}
        P_{\text{Babylon}} = \begin{pmatrix}
            a & 0 & 0 & 0 \\
            0 & b & 0 & 0 \\
            0 & 0 & \frac{f}{f-n} & \frac{-nf}{f-n} \\
            0 & 0 & 1 & 0
        \end{pmatrix}
    \end{equation}
    }

    Mapowanie na tablicę \texttt{\_m[]} (row-major, Babylon.js):

    \begin{center}
    {\scriptsize
    \begin{tabular}{|c|c|c|c|}
        \hline
        \texttt{\_m[0]}$\!=\!a$ & \texttt{\_m[1]}$\!=\!0$ & \texttt{\_m[2]}$\!=\!0$ & \texttt{\_m[3]}$\!=\!0$ \\
        \hline
        \texttt{\_m[4]}$\!=\!0$ & \texttt{\_m[5]}$\!=\!b$ & \texttt{\_m[6]}$\!=\!0$ & \texttt{\_m[7]}$\!=\!0$ \\
        \hline
        \texttt{\_m[8]}$\!=\!0$ & \texttt{\_m[9]}$\!=\!0$ & \texttt{\_m[10]}$\!=\!\frac{f}{f\!-\!n}$ & \texttt{\_m[11]}$\!=\!1$ \\
        \hline
        \texttt{\_m[12]}$\!=\!0$ & \texttt{\_m[13]}$\!=\!0$ & \texttt{\_m[14]}$\!=\!\frac{-nf}{f\!-\!n}$ & \texttt{\_m[15]}$\!=\!0$ \\
        \hline
    \end{tabular}
    }
    \end{center}

    \textbf{Kluczowa różnica LH vs RH}: element \texttt{\_m[11]} $= +1$ (lewoskrętny). W~systemach prawoskrętnych (OpenGL) jest $-1$.

    Mnożenie wektora $(x, y, z, 1)$ przez tę macierz daje:
    \begin{align}
        x_c &= a \cdot x = \frac{x}{ar \cdot \tan(fovy/2)} \\
        y_c &= b \cdot y = \frac{y}{\tan(fovy/2)} \\
        z_c &= \frac{fz}{f-n} - \frac{nf}{f-n} \\
        w' &= z
    \end{align}

    \item \textbf{Clip $\to$ NDC} (perspective divide): Dzielenie każdej składowej przez $w' = z$:
    \begin{align}
        x_n &= \frac{x_c}{w'} = \frac{x}{z \cdot ar \cdot \tan(fovy/2)}, \\
        y_n &= \frac{y_c}{w'} = \frac{y}{z \cdot \tan(fovy/2)}, \\
        z_n &= \frac{z_c}{w'} = \frac{f}{f-n} - \frac{nf}{z(f-n)} = \frac{f(z-n)}{z(f-n)}
    \end{align}

    Zakres $z_n$:
    \begin{itemize}
        \item $z = n$ (near): $z_n = \frac{f(n-n)}{n(f-n)} = 0$
        \item $z = f$ (far): $z_n = \frac{f(f-n)}{f(f-n)} = 1$
    \end{itemize}

    Więc $z_n \in [0, 1]$ w~Babylon.js (LH). Zależność od $z$ jest \textbf{nieliniowa} - hiperboliczna ($\propto 1/z$), co daje większą precyzję blisko kamery:


    W~Babylon.js (LH) obiekty widoczne mają $z > 0$, więc $w' = z > 0$, $x_n, y_n \in [-1, 1]$, $z_n \in [0, 1]$.

    \item \textbf{NDC $\to$ Screen [mm]}:

    Skalowanie na fizyczne wymiary ekranu: $x_d = x_n \cdot w/2$, \; $y_d = y_n \cdot h/2$.

    \textbf{Dlaczego $w/2$, a~nie $w$?} NDC ma zakres $x_n \in [-1, +1]$, czyli szerokość~$2$. Ekran ma zakres $x_d \in [-w/2, +w/2]$, czyli szerokość~$w$~[mm]. Współczynnik skali to stosunek zakresów:
    \begin{equation}
        \text{skala} = \frac{w}{2}
        \qquad \Longrightarrow \qquad
        x_d = x_n \cdot \frac{w}{2}
    \end{equation}
    Analogicznie dla $y$: $y_d = y_n \cdot h/2$.
\end{enumerate}

\subsubsection{Uproszczenie: co się skraca?}

Dla naszego celu (pozycja na ekranie w~mm) kroki 2--4 można połączyć. Kluczowa obserwacja: $n$ i~$f$ (near/far) \textbf{znikają} z~wyniku końcowego. Dowód:

Weźmy punkt $(x, y, z)$ w~układzie kamery ($z > 0$). Po macierzy $P$:
\begin{equation}
    x_c = \frac{x}{ar \cdot \tan(fovy/2)}, \qquad w' = z
\end{equation}

Po perspective divide: $x_n = x_c / w' = \frac{x}{z \cdot ar \cdot \tan(fovy/2)}$

Po skalowaniu na mm: $x_d = x_n \cdot w/2 = \frac{x \cdot w}{2z \cdot ar \cdot \tan(fovy/2)}$

Ponieważ $ar = w/h$:
\begin{equation}
    x_d = \frac{x \cdot h}{2z \cdot \tan(fovy/2)} = \frac{s \cdot x}{z}
\end{equation}

Definiujemy \textbf{s}:

\begin{equation} \label{eq:focal_length_mm}
    \boxed{s \;\equiv\; \frac{h}{2\,\tan\!\big(\frac{fovy}{2}\big)}}
    \quad\text{[mm]}
\end{equation}

Wtedy:
\begin{equation}
    \boxed{x_d = \frac{s \cdot x}{z}, \qquad y_d = \frac{s \cdot y}{z}}
    \qquad (z > 0, \text{ Babylon.js LH})
\end{equation}


\subsubsection{Po co jest $s$?}

Dzięki $s$ trzy kroki zwijają się do $x_d = sx/z$. To pozwoli otrzymać \textbf{jedną macierz $4\times 4$}.


Każda kamera ""widzi'' przez \textbf{ściętą piramidę} (frustum) - bryłę ograniczoną przez cztery boczne płaszczyzny, near ($z = n$) i~far ($z = f$). Wierzchołek w~pozycji kamery, kamera patrzy wzdłuż $+z$ (Babylon.js LH).

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{"D:/3DP/Code/JsGaussyVirtualTwoCams/docs/teoria/gl_projectionmatrix01.png"}
\caption{Frustum z boku. Punkt $(x,y,z)$ rzutowany na near plane przez podobieństwo trójkątów.}
\label{fig:frustum}
\end{figure}

\subsection{Rodzaje Projekcji}


W~Babylon.js dostępne są dwa tryby projekcji:
\begin{itemize}
    \item \texttt{Camera.PERSPECTIVE\_CAMERA} - \textbf{domyślny}
    \item \texttt{Camera.ORTHOGRAPHIC\_CAMERA}
\end{itemize}

Do stereo 3D na ekranie lentykularnym używamy \textbf{perspektywicznego}.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.42, >=latex, font=\tiny]
    % ===== PERSPEKTYWICZNY (left) =====
    \begin{scope}[shift={(-4.3,0)}]
    \node[font=\scriptsize\bfseries] at (0,6.3) {Perspektywiczny};
    \node[gray] at (0,5.8) {\texttt{PerspectiveFovLH}};

    \fill (0,0) circle(2pt);
    \node[below] at (0,-0.1) {kamera};

    % Frustum (trapezoid expanding with +z)
    \fill[yellow!15] (-0.7,1) -- (0.7,1) -- (2.4,5.2) -- (-2.4,5.2) -- cycle;
    \draw[blue!70,thick] (-0.7,1) -- (0.7,1);
    \draw[red!70,thick] (-2.4,5.2) -- (2.4,5.2);
    \draw[thick] (-0.7,1) -- (-2.4,5.2);
    \draw[thick] (0.7,1) -- (2.4,5.2);
    \draw[gray,dashed] (0,0)--(-0.7,1);
    \draw[gray,dashed] (0,0)--(0.7,1);

    % FOV
    \draw[gray] (0,0.5) arc[start angle=90,end angle=126,radius=0.5];
    \draw[gray] (0,0.5) arc[start angle=90,end angle=54,radius=0.5];
    \node[gray] at (0,0.78) {fov};

    % Same-size objects at different depths
    \draw[orange!80!black, fill=orange!20, thick] (-0.4,2) rectangle (0.4,2.5);
    \node[right, orange!80!black] at (0.5,2.25) {A};
    \draw[blue!70!black, fill=blue!10, thick] (-0.4,4) rectangle (0.4,4.5);
    \node[right, blue!70!black] at (0.5,4.25) {B};

    % Projection lines from camera to objects
    \draw[orange!60,dashed,thin] (0,0) -- (-0.4,2);
    \draw[orange!60,dashed,thin] (0,0) -- (0.4,2.5);
    \draw[blue!50,dashed,thin] (0,0) -- (-0.4,4);
    \draw[blue!50,dashed,thin] (0,0) -- (0.4,4.5);

    % Width annotations
    \draw[<->,gray,thin] (-2.4,5.5) -- (2.4,5.5);
    \node[above,gray] at (0,5.5) {szeroko};
    \draw[<->,gray,thin] (-0.7,0.7) -- (0.7,0.7);
    \node[below,gray] at (0,0.6) {wąsko};

    % Axis
    \draw[gray,->] (0,0) -- (0,5.8);
    \node[left,gray] at (-0.15,3) {$+z$};

    \node[blue!70,left] at (-0.8,1) {$n$};
    \node[red!70,left] at (-2.5,5.2) {$f$};
    \end{scope}

    % ===== ORTOGONALNY (right) =====
    \begin{scope}[shift={(4.3,0)}]
    \node[font=\scriptsize\bfseries] at (0,6.3) {Ortogonalny};
    \node[gray] at (0,5.8) {\texttt{OrthoLH}};

    \draw[thick] (-1.6,0) -- (1.6,0);
    \node[below] at (0,-0.1) {kamera};

    % Frustum (rectangle!)
    \fill[green!10] (-1.6,1) -- (1.6,1) -- (1.6,5.2) -- (-1.6,5.2) -- cycle;
    \draw[blue!70,thick] (-1.6,1) -- (1.6,1);
    \draw[red!70,thick] (-1.6,5.2) -- (1.6,5.2);
    \draw[thick] (-1.6,1) -- (-1.6,5.2);
    \draw[thick] (1.6,1) -- (1.6,5.2);

    % Parallel arrows
    \foreach \x in {-0.9,0,0.9}
        \draw[gray,->,thin] (\x,0.3) -- (\x,0.9);

    % Same-size objects at different depths (SAME apparent size!)
    \draw[orange!80!black, fill=orange!20, thick] (-0.4,2) rectangle (0.4,2.5);
    \node[right, orange!80!black] at (0.5,2.25) {A};
    \draw[blue!70!black, fill=blue!10, thick] (-0.4,4) rectangle (0.4,4.5);
    \node[right, blue!70!black] at (0.5,4.25) {B};

    % Parallel projection lines
    \draw[orange!50,dashed,thin] (-0.4,0.3) -- (-0.4,2);
    \draw[orange!50,dashed,thin] (0.4,0.3) -- (0.4,2.5);
    \draw[blue!40,dashed,thin] (-0.4,0.3) -- (-0.4,4);
    \draw[blue!40,dashed,thin] (0.4,0.3) -- (0.4,4.5);

    % Width annotations (same!)
    \draw[<->,gray,thin] (-1.6,5.5) -- (1.6,5.5);
    \node[above,gray] at (0,5.5) {stałe};
    \draw[<->,gray,thin] (-1.6,0.7) -- (1.6,0.7);
    \node[below,gray] at (0,0.6) {stałe};

    % Axis
    \draw[gray,->] (0,0) -- (0,5.8);
    \node[left,gray] at (-0.15,3) {$+z$};

    \node[blue!70,right] at (1.7,1) {$n$};
    \node[red!70,right] at (1.7,5.2) {$f$};
    \end{scope}

    % Separator
    \draw[gray!30,dashed] (0,-0.3) -- (0,6.3);
\end{tikzpicture}
\caption{Kształty frustumów (widok z~boku, oś $+z$ wzdłuż kierunku patrzenia kamery). \textbf{Perspektywiczny}: ścięta piramida - pole widzenia rozszerza się z~odległością. \textbf{Ortogonalny}: prostopadłościan - stała szerokość niezależnie od $z$.}
\label{fig:persp_vs_ortho}
\end{figure}



\begin{center}
{\scriptsize
\begin{tabular}{l c c}
    \hline
    & \textbf{Perspektywiczny} & \textbf{Ortogonalny} \\
    \hline
    Kształt frustum & ścięta piramida & prostopadłościan \\
    Promienie & zbieżne & równoległe \\
    Rozmiar na ekranie & $\propto 1/z$ & stały \\
    Wzór projekcji & $x_d = sx/z$ & $x_d = k \cdot x$ \\
    Macierz Babylon.js & \texttt{PerspectiveFovLH} & \texttt{OrthoLH} \\
    Efekt 3D stereo & \textbf{tak} & \textbf{nie} \\
    \hline
\end{tabular}
}
\end{center}

\textbf{Dlaczego perspektywiczny?} Stereoskopia wymaga, aby rozmiar obrazu na ekranie zależał od głębokości $z$ - to daje $x_d = sx/z$. Dysparyczność:
\begin{equation}
    \Delta = x_{dl} - x_{dr} = \frac{sD}{Z} \propto \frac{1}{Z}
\end{equation}
W~projekcji ortogonalnej dysparyczność $\Delta = kD$ byłaby stała (nie zależy od $Z$) - \textbf{brak informacji o~głębokości}, stereoskopia nie działa.

\subsection{Krok 1 (wynik): Dwie wirtualne kamery Babylon.js}

Mamy dwie kamery Babylon.js o~równoległych osiach optycznych (obie patrzą wzdłuż $+z$), rozstawione symetrycznie:
\begin{align}
    \text{Lewa kamera:} \quad & (-D/2,\; 0,\; 0) \\
    \text{Prawa kamera:} \quad & (+D/2,\; 0,\; 0)
\end{align}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.44, >=latex, font=\tiny]

    % ============ PARAMETRY GLOBALNE ============
    \def\halfIPD{1.8}          % D/2 - połowa bazy stereo
    \def\zNear{1.0}            % near plane
    \def\zFar{10.0}            % far plane (linia odcięcia)

    % ============ KĄTY FOV (w stopniach od osi optycznej) ============
    % Lewa kamera: kąt w lewo (temporal) i w prawo (nasal)
    \def\leftCamFovLeft{25}    % FOV w lewo od osi (temporal)
    \def\leftCamFovRight{45}   % FOV w prawo od osi (nasal, węższy)

    % Prawa kamera: symetrycznie lub asymetrycznie
    \def\rightCamFovLeft{45}   % FOV w lewo od osi (nasal)
    \def\rightCamFovRight{25}  % FOV w prawo od osi (temporal)

    % ============ OBLICZENIA AUTOMATYCZNE ============
    % Lewa kamera (-halfIPD, 0)
    \pgfmathsetmacro{\LnearL}{-\halfIPD - \zNear * tan(\leftCamFovLeft)}
    \pgfmathsetmacro{\LnearR}{-\halfIPD + \zNear * tan(\leftCamFovRight)}
    \pgfmathsetmacro{\LfarL} {-\halfIPD - \zFar  * tan(\leftCamFovLeft)}
    \pgfmathsetmacro{\LfarR} {-\halfIPD + \zFar  * tan(\leftCamFovRight)}

    % Prawa kamera (+halfIPD, 0)
    \pgfmathsetmacro{\RnearL}{\halfIPD - \zNear * tan(\rightCamFovLeft)}
    \pgfmathsetmacro{\RnearR}{\halfIPD + \zNear * tan(\rightCamFovRight)}
    \pgfmathsetmacro{\RfarL} {\halfIPD - \zFar  * tan(\rightCamFovLeft)}
    \pgfmathsetmacro{\RfarR} {\halfIPD + \zFar  * tan(\rightCamFovRight)}

    % ============ RYSOWANIE ============

    % Osie
    \draw[->, gray, thick] (-7, 0) -- (7, 0) node[right] {$x$};
    \draw[->, gray, thick] (0, -1) -- (0, 13) node[above] {$z$};
    \node[gray, font=\scriptsize] at (0.3, 0.3) {$0$};

    % Near/far planes
    \draw[dashed, gray!50] (-7, \zNear) -- (7, \zNear)
        node[right, font=\scriptsize] {near $z_n$};
    \draw[dashed, gray!50] (-7, \zFar)  -- (7, \zFar)
        node[right, font=\scriptsize] {far $z_f$};

    % --- Lewy frustum (fill + edges) ---
    \fill[red!8, opacity=0.4]
        (\LnearL, \zNear) -- (\LfarL, \zFar)
        -- (\LfarR, \zFar) -- (\LnearR, \zNear) -- cycle;
    \draw[red!50, thick] (-\halfIPD, 0) -- (\LfarL, \zFar);   % lewa krawędź
    \draw[red!50, thick] (-\halfIPD, 0) -- (\LfarR, \zFar);   % prawa krawędź
    \draw[red!50] (\LnearL, \zNear) -- (\LnearR, \zNear);     % near plane clip
    \draw[red!50] (\LfarL, \zFar)   -- (\LfarR, \zFar);       % far plane clip

    % Oś optyczna lewej kamery
    \draw[red!30, dashed] (-\halfIPD, 0) -- (-\halfIPD, 12);
    \node[above, red!70!black, font=\scriptsize] at (-\halfIPD -2, 12) {Oś optyczna L};

    % --- Prawy frustum (fill + edges) ---
    \fill[green!8, opacity=0.4]
        (\RnearL, \zNear) -- (\RfarL, \zFar)
        -- (\RfarR, \zFar) -- (\RnearR, \zNear) -- cycle;
    \draw[green!50, thick] (\halfIPD, 0) -- (\RfarL, \zFar);   % lewa krawędź
    \draw[green!50, thick] (\halfIPD, 0) -- (\RfarR, \zFar);   % prawa krawędź
    \draw[green!50] (\RnearL, \zNear) -- (\RnearR, \zNear);    % near plane clip
    \draw[green!50] (\RfarL, \zFar)   -- (\RfarR, \zFar);      % far plane clip

    % Oś optyczna prawej kamery
    \draw[green!30, dashed] (\halfIPD, 0) -- (\halfIPD, 12);
    \node[above, green!70!black, font=\scriptsize] at (\halfIPD +2, 12) {Oś optyczna R};

    % --- Kamery ---
    \fill[red!70!black]   (-\halfIPD, 0) circle (3pt);
    \fill[green!50!black]  (\halfIPD, 0) circle (3pt);
    \node[below, red!70!black, font=\scriptsize]   at (-\halfIPD, -0.15) {L};
    \node[below, red!70!black] at (-\halfIPD, -0.8) {$(-\frac{D}{2}, 0, 0)$};
    \node[below, green!50!black, font=\scriptsize] at ( \halfIPD, -0.15) {R};
    \node[below, green!50!black] at (\halfIPD, -0.8) {$(+\frac{D}{2}, 0, 0)$};

    % Baza stereo
    \draw[|<->|, thin] (-\halfIPD, -2) -- node[below] {$D$ (baza stereo)} (\halfIPD, -2);

\end{tikzpicture}
\caption{Setup stereo. Dwie kamery \textbf{perspektywiczne} L i~R, rozstawione o~$D$}
\label{fig:stereo_setup}
\end{figure}

Punkt sceny $(X, Y, Z)$ we~współrzędnych świata Babylon.js ($Z > 0$). Aby go rzutować, musimy najpierw przeliczyć na \textbf{układ kamery} (krok View).

\paragraph{Transformacja World $\to$ View (\texttt{camera.getViewMatrix()}).}
Kamery patrzą wzdłuż $+z$ i~są przesunięte tylko wzdłuż $x$. Macierz View to czysta translacja - przesuwa scenę tak, żeby kamera znalazła się w~początku układu:

Dla lewej kamery (przesunięcie o~$+D/2$):
\begin{equation}
    \begin{pmatrix} x \\ y \\ z \end{pmatrix}_{\text{view}_L}
    = \begin{pmatrix} X - (-D/2) \\ Y \\ Z \end{pmatrix}
    = \begin{pmatrix} X + D/2 \\ Y \\ Z \end{pmatrix}
\end{equation}

Dla prawej kamery (przesunięcie o~$-D/2$):
\begin{equation}
    \begin{pmatrix} x \\ y \\ z \end{pmatrix}_{\text{view}_R}
    = \begin{pmatrix} X - D/2 \\ Y \\ Z \end{pmatrix}
\end{equation}

\paragraph{Projekcja perspektywiczna + skalowanie na mm.}
Stosujemy wzór $x_d = sx/z$ (wyprowadzony wcześniej, LH) do każdej kamery:

\medskip
\textbf{Lewa kamera} - punkt w~jej układzie to $(X + D/2,\; Y,\; Z)$:
\begin{equation}
    x_{dl} = \frac{s \cdot (X + D/2)}{Z}
    = \frac{sX}{Z} + \frac{sD}{2Z}
\end{equation}

\textbf{Prawa kamera} - punkt w~jej układzie to $(X - D/2,\; Y,\; Z)$:
\begin{equation}
    x_{dr} = \frac{s \cdot (X - D/2)}{Z}
    = \frac{sX}{Z} - \frac{sD}{2Z}
\end{equation}

\textbf{Współrzędna $y$} jest taka sama dla obu kamer (rozstaw tylko w~$x$):
\begin{equation}
    y_d = \frac{s \cdot Y}{Z}
\end{equation}

\paragraph{Dysparyczność metryczna i~punkt środkowy.}
Odejmujemy $x_{dl} - x_{dr}$:
\begin{equation}
    x_{dl} - x_{dr} = \Big(\frac{sX}{Z} + \frac{sD}{2Z}\Big) - \Big(\frac{sX}{Z} - \frac{sD}{2Z}\Big) = \frac{sD}{2Z} + \frac{sD}{2Z}
\end{equation}

\begin{equation}
    \boxed{x_{dl} - x_{dr} = \frac{sD}{Z}} \label{eq:metric_disparity}
\end{equation}

Dysparyczność metryczna jest \textbf{proporcjonalna do bazy stereo $D$} i~\textbf{odwrotnie proporcjonalna do głębokości $Z$}. To jest fundamentalny wzór stereowizji: $\Delta \propto D/Z$.

\textbf{Uwaga (Babylon.js LH)}: $Z > 0$, więc dysparyczność jest \textbf{zawsze dodatnia} - odpowiada obiektom przed ekranem (paralaksa ujemna/skrzyżowana). Aby obiekty mogły się pojawiać \emph{za} ekranem, potrzebna jest konwergencja (off-axis shift) - patrz uwaga na końcu sekcji.

Punkt środkowy (średnia arytmetyczna lewego i~prawego):
\begin{equation}
    \frac{x_{dl} + x_{dr}}{2} = \frac{1}{2}\Big(\frac{sX}{Z} + \frac{sD}{2Z} + \frac{sX}{Z} - \frac{sD}{2Z}\Big) = \frac{sX}{Z} \label{eq:midpoint}
\end{equation}

Punkt środkowy nie zależy od $D$ - jest taki sam jak projekcja z~jednej kamery centralnej.

\paragraph{Po co punkt środkowy?}
We wzorze na postrzegany punkt 3D (sekcja~\ref{sec:perceived_point}) współrzędna $x_t$ ma postać:
\begin{equation}
    x_t = x_u + \underbrace{\frac{d}{d + \Delta}}_{\text{współczynnik}} \cdot \Big(\underbrace{\frac{x_{dl}+x_{dr}}{2}}_{\text{punkt śr.}} - x_u\Big)
\end{equation}


Punkt środkowy wyznacza \textbf{kierunek promienia wzroku} od użytkownika do ekranu. Dysparyczność $\Delta$ decyduje \textbf{jak daleko} wzdłuż tego promienia leży postrzegany punkt:
\begin{itemize}
    \item $\Delta = 0$: punkt na ekranie (lewy i~prawy obraz pokrywają się)
    \item $\Delta > 0$: punkt przed ekranem (bliżej użytkownika)
    \item $\Delta < 0$: punkt za ekranem (dalej od użytkownika, wymaga konwergencji)
\end{itemize}

Dzięki rozbiciu na punkt środkowy + dysparyczność, wzór separuje \textbf{kierunek} (gdzie na ekranie) od \textbf{głębokości} (jak daleko od ekranu).

\paragraph{Uogólnienie wektorowe - model oka cyklopowego.}
Wszystkie trzy współrzędne postrzeganego punktu (sekcja~\ref{sec:perceived_point}) mają \textbf{identyczną strukturę}:
\begin{align}
    x_t &= x_u + \frac{d}{d+\Delta}\Big(\frac{x_{dl}+x_{dr}}{2} - x_u\Big) \\[4pt]
    y_t &= y_u + \frac{d}{d+\Delta}\big(y_d - y_u\big) \\[4pt]
    z_t &= z_u + \frac{d}{d+\Delta}\big(\underbrace{0}_{z_{\text{ekran}}} - z_u\big)
\end{align}

Definiujemy:
\begin{itemize}
    \item $\vec{U} = (x_u,\; y_u,\; z_u)$ - \textbf{środek między oczami},
    \item $\vec{M} = \Big(\frac{x_{dl}+x_{dr}}{2},\; y_d,\; 0\Big)$ - \textbf{punkt środkowy} na ekranie,
    \item $\lambda = \frac{d}{d + \Delta}$ - skalar zależny \textbf{tylko} od dysparyczności.
\end{itemize}

Wtedy cały wzór to \textbf{równanie parametryczne prostej} przez $\vec{U}$ i~$\vec{M}$:

\begin{equation}
    \boxed{\vec{P}_t = \vec{U} + \lambda \cdot \big(\vec{M} - \vec{U}\big)}
    \label{eq:cyclopean_ray}
\end{equation}

Wektor $\vec{M} - \vec{U}$ wyznacza \textbf{kierunek} promienia od oka cyklopowego do ekranu. Skalar $\lambda(\Delta)$ mówi \textbf{jak daleko} wzdłuż tego promienia leży postrzegany punkt:

\begin{center}
{\small
\begin{tabular}{c c l}
    \hline
    $\Delta$ & $\lambda$ & \textbf{Interpretacja} \\
    \hline
    $0$ & $1$ & $\vec{P}_t = \vec{M}$ - punkt \textbf{na ekranie} \\
    $> 0$ & $< 1$ & punkt \textbf{przed} ekranem (bliżej użytkownika) \\
    $\in (-d, 0)$ & $> 1$ & punkt \textbf{za} ekranem \\
    $\to -d$ & $\to +\infty$ & punkt \textbf{w~nieskończoności} \\
    \hline
\end{tabular}
}
\end{center}


\subsection{Krok 2: Podstawienie do paralaksy}

Podstawiamy (\ref{eq:metric_disparity}) i~(\ref{eq:midpoint}) do wzoru~(\ref{eq:perceived_point}):

\begin{equation}
    d + x_{dl} - x_{dr} = d + \frac{sD}{Z} = \frac{dZ + sD}{Z}
\end{equation}

\begin{equation}
    \frac{d}{d + x_{dl} - x_{dr}} = \frac{dZ}{dZ + sD}
\end{equation}

Dla $z_t$:
{\small
\begin{equation}
    z_t = z_u\!\left(1 - \frac{dZ}{dZ + sD}\right) = z_u \cdot \frac{sD}{dZ + sD} = \frac{sDz_u}{sD + dZ}
\end{equation}
}

Dla $x_t$:
{\small
\begin{equation}
    x_t = x_u + \frac{dZ}{dZ + sD}\!\left(\frac{sX}{Z} - x_u\right)
\end{equation}
\begin{equation}
    = \frac{x_u(dZ + sD) + dsX - dx_uZ}{dZ + sD}
\end{equation}
\begin{equation}
    = \frac{\cancel{x_u dZ} + x_u sD + dsX - \cancel{dx_uZ}}{dZ + sD}
\end{equation}
\begin{equation}
    x_t = \frac{s(Dx_u + dX)}{sD + dZ}
\end{equation}
}

Analogicznie:
\begin{equation}
    y_t = \frac{s(Dy_u + dY)}{sD + dZ}
\end{equation}

\subsection{Wynik: zwarta postać wektorowa}

\begin{equation} \label{eq:compact_vector}
    \boxed{
    \begin{pmatrix} x_t \\ y_t \\ z_t \end{pmatrix}
    = \frac{s}{sD + dZ}
    \begin{pmatrix} Dx_u + dX \\ Dy_u + dY \\ Dz_u \end{pmatrix}
    }
\end{equation}

Wspólny mianownik $sD + dZ > 0$ zawsze (bo $Z > 0$, $s, D, d > 0$ w~Babylon.js LH).

\subsection{Macierz $4\times 4$ we~wsp. jednorodnych}

Wzór (\ref{eq:compact_vector}) jest funkcją wymierną ($Z$ w~mianowniku), więc w~zwykłych wsp.\ 3D nie da się go zapisać jako macierz $3\times 3$. Ale we~\textbf{wsp.\ jednorodnych} - tak. Pokażemy to krok po kroku.

\paragraph{Krok A: Problem - $Z$ w~mianowniku.}
Zapiszmy jawnie każdą współrzędną z~(\ref{eq:compact_vector}):
\begin{align}
    x_t &= \frac{s(Dx_u + dX)}{sD + dZ} \label{eq:xt_explicit}\\[4pt]
    y_t &= \frac{s(Dy_u + dY)}{sD + dZ} \label{eq:yt_explicit}\\[4pt]
    z_t &= \frac{sDz_u}{sD + dZ} \label{eq:zt_explicit}
\end{align}

Mianownik $w' = sD + dZ$ zależy od $Z$ - to funkcja \textbf{nieliniowa} (wymierna), więc zwykła macierz $3\times 3$ (mnożenie $A\mathbf{v}$) nie potrafi dzielić przez liniową kombinację składowych.

\paragraph{Krok B: Idea wsp.\ jednorodnych.}
We wsp.\ jednorodnych punkt 3D $(x, y, z)$ reprezentujemy jako wektor 4D:
\begin{equation}
    (x, y, z) \quad\longleftrightarrow\quad
    \begin{pmatrix} x \cdot w \\ y \cdot w \\ z \cdot w \\ w \end{pmatrix}
    \quad \text{dla dowolnego } w \neq 0
\end{equation}
Odzyskanie 3D: dzielimy przez ostatnią składową $w$. Kluczowa obserwacja: \textbf{$w$ może być funkcją danych wejściowych!}

\paragraph{Krok C: Mnożymy obie strony przez $w'$.}
Zamiast zapisywać $x_t, y_t, z_t$ bezpośrednio, zapiszmy \textbf{liczniki} - iloczyn $w' \cdot x_t$ itd.:
\begin{align}
    w' \cdot x_t &= s(Dx_u + dX) = sdX + sDx_u \label{eq:num_x}\\[2pt]
    w' \cdot y_t &= s(Dy_u + dY) = sdY + sDy_u \label{eq:num_y}\\[2pt]
    w' \cdot z_t &= sDz_u \label{eq:num_z}\\[2pt]
    w' &= dZ + sD \label{eq:num_w}
\end{align}

Każdy z~tych wyrażeń jest teraz \textbf{liniowy} względem $(X, Y, Z, 1)$ - nie ma dzielenia!

\paragraph{Krok D: Szukamy macierzy $M$.}
Chcemy znaleźć macierz $M$ taką, że:
\begin{equation}
    \underbrace{\begin{pmatrix} w' x_t \\ w' y_t \\ w' z_t \\ w' \end{pmatrix}}_{\text{jednorodny wynik}}
    = M \cdot
    \begin{pmatrix} X \\ Y \\ Z \\ 1 \end{pmatrix}
\end{equation}

Porównujemy wiersz po wierszu z~(\ref{eq:num_x})--(\ref{eq:num_w}):

\textbf{Wiersz 1} ($w' x_t = sdX + sDx_u$):
\begin{equation}
    \begin{pmatrix} m_{11} & m_{12} & m_{13} & m_{14} \end{pmatrix}
    \begin{pmatrix} X \\ Y \\ Z \\ 1 \end{pmatrix}
    = sd \cdot X + 0 \cdot Y + 0 \cdot Z + sDx_u \cdot 1
\end{equation}
Zatem: $m_{11} = sd$, $m_{12} = 0$, $m_{13} = 0$, $m_{14} = sDx_u$.

\textbf{Wiersz 2} ($w' y_t = sdY + sDy_u$):
\begin{equation}
    m_{21} = 0, \quad m_{22} = sd, \quad m_{23} = 0, \quad m_{24} = sDy_u
\end{equation}

\textbf{Wiersz 3} ($w' z_t = sDz_u$):
\begin{equation}
    m_{31} = 0, \quad m_{32} = 0, \quad m_{33} = 0, \quad m_{34} = sDz_u
\end{equation}
(Nie zależy od $X, Y, Z$ - cały wiersz to zera i~stała!)

\textbf{Wiersz 4} ($w' = dZ + sD$):
\begin{equation}
    m_{41} = 0, \quad m_{42} = 0, \quad m_{43} = d, \quad m_{44} = sD
\end{equation}

\paragraph{Krok E: Składamy macierz.}

{\small
\begin{equation} \label{eq:homogeneous}
    \boxed{
    \begin{pmatrix} x_t \\ y_t \\ z_t \\ 1 \end{pmatrix}
    = \frac{1}{w'}
    \underbrace{
    \begin{pmatrix}
        sd & 0  & 0  & sDx_u \\
        0  & sd & 0  & sDy_u \\
        0  & 0  & 0  & sDz_u \\
        0  & 0  & d  & sD
    \end{pmatrix}
    }_{M_{\mathrm{SP}}}
    \begin{pmatrix} X \\ Y \\ Z \\ 1 \end{pmatrix}
    }
\end{equation}
}

\noindent $M_{\mathrm{SP}}$ -- \textbf{Macierz stereo-percepcji} (Stereo Perception Matrix).

gdzie $w'$ to 4.\ składowa wyniku: $w' = d \cdot Z + sD \cdot 1 = dZ + sD$.

\medskip
\textbf{Weryfikacja} (iloczyn $M \cdot \mathbf{v}$ wiersz po wierszu):
\begin{itemize}
    \item wiersz 1: $sd \cdot X + sDx_u \cdot 1 = s(dX + Dx_u)$ \; $\div\, w'$ \; $\to$ \; (\ref{eq:xt_explicit}) 
    \item wiersz 2: $sd \cdot Y + sDy_u \cdot 1 = s(dY + Dy_u)$ \; $\div\, w'$ \; $\to$ \; (\ref{eq:yt_explicit}) 
    \item wiersz 3: $sDz_u \cdot 1$ \; $\div\, w'$ \; $\to$ \; (\ref{eq:zt_explicit}) 
    \item wiersz 4: $d \cdot Z + sD \cdot 1 = w'$ \; $\div\, w'$ \; $= 1$ 
\end{itemize}

\paragraph{Dlaczego macierz $3\times 3$ nie wystarczy?}

Nasza formuła ma postać:
\begin{equation}
    x_t = \frac{sdX + sDx_u}{dZ + sD}
\end{equation}

To jest \textbf{funkcja wymierna} (ułamek dwóch wielomianów liniowych). Macierz $3\times 3$ potrafi tylko generować \textbf{funkcje liniowe}:

\begin{equation}
    \begin{pmatrix} x_t \\ y_t \\ z_t \end{pmatrix}
    = A_{3\times 3}
    \begin{pmatrix} X \\ Y \\ Z \end{pmatrix}
    \quad\Longrightarrow\quad
    x_t = a_{11}X + a_{12}Y + a_{13}Z
\end{equation}

\textbf{Dowód, że to niemożliwe.} Funkcja liniowa musi spełniać dwa warunki:

\textit{1.\ Jednorodność:} $f(\lambda \mathbf{v}) = \lambda \, f(\mathbf{v})$. Sprawdźmy:
\begin{equation}
    x_t(\lambda X, \lambda Y, \lambda Z) = \frac{sd \cdot \lambda X + sDx_u}{d \cdot \lambda Z + sD}
\end{equation}

Aby to równało się $\lambda \cdot x_t(X,Y,Z) = \lambda \cdot \frac{sdX + sDx_u}{dZ + sD}$, potrzebowalibyśmy:
\begin{equation}
    \frac{\lambda \, sdX + sDx_u}{\lambda \, dZ + sD}
    \stackrel{?}{=}
    \lambda \cdot \frac{sdX + sDx_u}{dZ + sD}
\end{equation}

To równość \textbf{fałszywa} - lewa strona ma $sDx_u$ (stałą) w~liczniku, prawa ma $\lambda \, sDx_u$. Mnożenie obu stron przez mianowniki daje:
\begin{equation}
    (\lambda\, sdX + sDx_u)(dZ + sD) \neq
    \lambda (sdX + sDx_u)(\lambda\, dZ + sD)
\end{equation}

\textit{2.\ Addytywność:} $f(\mathbf{u}+\mathbf{v}) = f(\mathbf{u}) + f(\mathbf{v})$ - również nie zachodzi, bo mianownik $dZ + sD$ jest \textbf{różny} dla różnych $Z$.

\medskip
\textbf{Wniosek:} $x_t(X,Y,Z)$ nie jest funkcją liniową $\Rightarrow$ \textbf{nie istnieje} macierz $3\times 3$ (ani $3\times 4$, ani żadna afiniczna) realizująca to odwzorowanie.

\paragraph{Jak wsp.\ jednorodne rozwiązują problem?}

Trik polega na \textbf{rozdzieleniu} obliczeń na dwa etapy:

\begin{center}
\begin{tikzpicture}[>=latex, font=\small, node distance=0.6cm]
    \node[draw, inner sep=4pt] (A) {$\begin{pmatrix} X \\ Y \\ Z \\ 1 \end{pmatrix}$};
    \node[draw, inner sep=4pt, right=1.8cm of A] (B) {$\begin{pmatrix} w'x_t \\ w'y_t \\ w'z_t \\ w' \end{pmatrix}$};
    \node[draw, inner sep=4pt, right=1.8cm of B] (C) {$\begin{pmatrix} x_t \\ y_t \\ z_t \\ 1 \end{pmatrix}$};
    \draw[->, thick] (A) -- node[above, font=\tiny] {$M_{4\times 4}$} node[below, font=\tiny] {liniowe!} (B);
    \draw[->, thick] (B) -- node[above, font=\tiny] {$\div\, w'$} node[below, font=\tiny] {nieliniowe!} (C);
\end{tikzpicture}
\end{center}

\begin{enumerate}
    \item \textbf{Etap liniowy} (macierz $M$): Oblicza \textbf{liczniki} $w'x_t, w'y_t, w'z_t$ oraz \textbf{mianownik} $w'$. Wszystkie są liniowe w~$(X,Y,Z,1)$ - więc macierz radzi sobie idealnie.

    \item \textbf{Etap nieliniowy} (dehomogenizacja z angielska ): Dzieli przez $w'$. To jest jedyna operacja nieliniowa - i~dzieje się \textbf{poza macierzą}, na GPU w silnikach gier tak samo jest obliczana perspective divide.
\end{enumerate}

\paragraph{Analogia z~projekcją perspektywiczną.}

Ten sam mechanizm używa standardowa projekcja kamery:

\begin{center}
{\small
\begin{tabular}{lcc}
    & \textbf{Projekcja kamery} & \textbf{Nasza macierz $M$} \\
    \hline
    Licznik $x$ & $sx$ & $sdX + sDx_u$ \\
    Mianownik $w'$ & $z$ & $dZ + sD$ \\
    Wynik & $x_d = sx/z$ & $x_t = \frac{sdX+sDx_u}{dZ+sD}$ \\
    \hline
    Wiersz 4 macierzy & $(0,0,1,0)$ & $(0,0,d,sD)$ \\
\end{tabular}
}
\end{center}



\medskip
\medskip



\subsection{Interpretacja parametrów}

\begin{center}
{\scriptsize
\begin{tabular}{c l l}
    \hline
    \textbf{Sym.} & \textbf{Znaczenie} & \textbf{Jedn.} \\
    \hline
    $s$ & wirtualna 'ogniskowa' ekranowa $= \frac{h}{2\tan(fovy/2)}$ & jednostki sceny \\
    $d$ & IPD użytkownika & mm \\
    $D$ & baza stereo (kamer) & jednostki sceny  \\
    $(x_u,y_u,z_u)$ & pozycja użytkownika & mm \\
    $(X,Y,Z)$ & punkt w scenie & jednostki sceny  \\
    \hline
\end{tabular}
}
\end{center}
*wirtualna 'ogniskowa' ekranowa to parametr który określa jak daleko musze ustawic kamerę żeby to co widzi kamera z jej fov wypelniło mój cały ekran. Odpowiada to ogniskowej w soczewce która skupia promienie w taki sposób żeby to co widzi obiektyw wypełniłow całości sensor kamery

\subsection{\texorpdfstring{Właściwości macierzy $M_{\mathrm{SP}}$}{Właściwości macierzy M\_SP}}

\begin{enumerate}
    \item Transformacja odwrotna prawdopodobnie istnieje (trzeba policzyć $\det$ tej macierzy i~sprawdzić czy jest $\neq 0$). Macierz odwrotna $M_{\mathrm{SP}}^{-1}$ powinna z~postrzeganego punktu 3D odtworzyć punkt ww wirtualnej scenie 3D - $X$,$Y$,$Z$ np środowiska babilon, Unity, Unreal.

    \item Trzeci wiersz $(0,0,0,sDz_u)$ oznacza, że $z_t$ nie zależy od $X$ ani $Y$ - głębokość postrzegana zależy \textbf{tylko} od $Z$ i~$z_u$.

    \item Stosunek $D/d$ kontroluje skalę głębokości, biorąc wzor na $z_t$ i dzieląc licznik i mianoenik przez d otrzymujemy:
    \begin{equation}
        z_t = \frac{s \cdot D \cdot z_u}{sD + dZ}
        = \frac{s \cdot \frac{D}{d} \cdot z_u}{s \cdot \frac{D}{d} + Z}
    \end{equation}
    $D$ (baza stereo) i~$d$ (IPD) występują \textbf{wyłącznie} jako stosunek $D/d$ --- nigdy osobno. Ten stosunek skaluje dysparyczność: większy rozstaw kamer wirtualnych niż rozstaw oczu $\Rightarrow$ przesadzona dysparyczność $\Rightarrow$ przesadzona głębokość.
    \begin{itemize}
        \item $D/d > 1$: powiększona stereoskopia (efekt lornetki)
        \item $D/d = 1$: naturalna (1:1 z~rzeczywistością)
        \item $D/d < 1$: osłabiona (płaski obraz)
    \end{itemize}

\end{enumerate}


\section{Wzór ogólny - podsumowanie}
\label{sec:final_formula}

Dla punktu $(X, Y, Z)$ w~wirtualnej scenie Babylon.js~(LH) i~użytkownika w~pozycji $(x_u, y_u, z_u)$ przed ekranem:

\begin{equation}
    \boxed{
    \begin{pmatrix} x_t \\[4pt] y_t \\[4pt] z_t \end{pmatrix}
    = \frac{1}{w'}
    \begin{pmatrix}
        s(dX + Dx_u) \\[4pt]
        s(dY + Dy_u) \\[4pt]
        sDz_u
    \end{pmatrix}
    , \qquad w' = dZ + sD
    }
\end{equation}

\textbf{Równoważnie, jawnie:}
\begin{align}
    x_t &= \frac{s(dX + Dx_u)}{dZ + sD} \label{eq:final_xt}\\[6pt]
    y_t &= \frac{s(dY + Dy_u)}{dZ + sD} \label{eq:final_yt}\\[6pt]
    z_t &= \frac{sDz_u}{dZ + sD} \label{eq:final_zt}
\end{align}

\textbf{Jako macierz jednorodna $4\times 4$:}
{\small
\begin{equation}
    \begin{pmatrix} x_t \\ y_t \\ z_t \\ 1 \end{pmatrix}
    = \frac{1}{w'}
    \begin{pmatrix}
        sd & 0  & 0 & sDx_u \\
        0  & sd & 0 & sDy_u \\
        0  & 0  & 0 & sDz_u \\
        0  & 0  & d & sD
    \end{pmatrix}
    \begin{pmatrix} X \\ Y \\ Z \\ 1 \end{pmatrix}
\end{equation}
}

\textbf{5 parametrów:}
\begin{center}
{\small
\begin{tabular}{c p{50mm} c}
    \hline
    \textbf{Sym.} & \textbf{Znaczenie} \\
    \hline
    $s$ & ogniskowa    \\[4pt]
    $d$ & IPD  \\[2pt]
    $D$ & baza stereo wirtualnych kamer \\[2pt]
    $(x_u,y_u,z_u)$ & pozycja środka oczu użytkownika  \\[2pt]
    $(X,Y,Z)$ & punkt w wirtualnej scenie   \\
    \hline
\end{tabular}
}
\end{center}


\subsection{Problem: wszystko przed ekranem}

W~dotychczasowym wyprowadzeniu dysparyczność wynosi:
\begin{equation}
    \Delta = x_{dl} - x_{dr} = \frac{sD}{Z} > 0 \quad\text{(zawsze zakładaliśmy że $Z > 0$ w wirtualnej scenie dla uproszczenia obliczeń)}
\end{equation}

Dodatnia dysparyczność oznacza, że \textbf{wszystkie obiekty} są postrzegane \textbf{przed ekranem} (pop-out). Żaden obiekt nie może być postrzegany \textbf{za ekranem} (depth-in).

Na wyświetlaczu lentykularnym (Odyssey 3D) chcemy obu efektów - obiekty bliskie wyskakują z~ekranu, a~dalekie cofają się w~głąb. Wymaga to \textbf{konwergencji}.

\subsection{Konwergencja - off-axis projection}

Konwergencja to głębokość $Z_c$ w~scenie, przy której dysparyczność jest zerowa - obiekt na tej głębokości jest postrzegany dokładnie na powierzchni ekranu.


Matematycznie: do każdej projekcji dodajemy \textbf{stałe przesunięcie} (niezależne od $Z$), tak żeby przy $Z = Z_c$ obie kamery dawały ten sam punkt na ekranie. Wyprowadzamy te przesunięcia krok po kroku.

\paragraph{Krok A: Projekcje bez konwergencji (powtórzenie).}
Z~sekcji~\ref{sec:stereo_projection} mamy:
\begin{align}
    x_{dl}^{(0)} &= \frac{s(X + D/2)}{Z} \quad\text{(lewa kamera)} \\[3pt]
    x_{dr}^{(0)} &= \frac{s(X - D/2)}{Z} \quad\text{(prawa kamera)}
\end{align}
Dysparyczność (różnica) wynosi $\Delta^{(0)} = sD/Z > 0$ - \textbf{zawsze} pop-out.

\paragraph{Krok B: Dodajemy przesunięcia $\delta_L$, $\delta_R$.}
Modyfikujemy projekcje o~\textbf{stałe} (niezależne od~$X$,~$Z$) przesunięcia:
\begin{align}
    x_{dl} &= \frac{s(X + D/2)}{Z} + \delta_L \label{eq:xdl_shifted}\\[3pt]
    x_{dr} &= \frac{s(X - D/2)}{Z} + \delta_R \label{eq:xdr_shifted}
\end{align}

\medskip
\textbf{Czym jest frustum i~co oznacza ,,asymetryczny frustrum''?}

\textbf{Frustum} (z~łaciny: \emph{frustum} = ścięty) to bryła geometryczna w~kształcie ściętego ostrosłupa. W~grafice 3D frustum definiuje \textbf{pole widzenia kamery} - wszystko wewnątrz frustumu jest widoczne na ekranie, reszta jest odrzucana (ang.\ \emph{frustum culling}).

Frustum jest wyznaczony przez \textbf{6 płaszczyzn obcinania}:
\begin{itemize}
    \item \textbf{near plane} (bliski) - prostokąt na odległości $n$ od oka; to właśnie on odpowiada ekranowi/viewportowi
    \item \textbf{far plane} (daleki) - maksymalna głębokość renderowania
    \item 4 boczne ściany łączące near i~far plane
\end{itemize}


\textbf{Analiza - co zmienia się w~obrazie:}

\begin{enumerate}
    \item \textbf{Symetryczny frustum} - obiekt na głębokości $Z_c$ jest przesunięty:
    \begin{itemize}
        \item w~obrazie~L: \textbf{w prawo} od środka kadru (bo kamera L jest na lewo od obiektu)
        \item w~obrazie~R: \textbf{w lewo} od środka kadru (bo kamera R jest na prawo)
        \item dysparyczność $\Delta = sD/Z_c > 0$ - mózg widzi obiekt \textbf{przed} ekranem
        \item \textbf{każdy} obiekt ma $\Delta > 0$, nie da się umieścić niczego ,,za'' ekranem
    \end{itemize}

    \item \textbf{Asymetryczny frustum} (off-axis $\delta$):
    \begin{itemize}

        \item mózg widzi obiekt \textbf{na powierzchni ekranu}
        \item obiekty bliżej ($Z < Z_c$) nadal mają $\Delta > 0$ - pop-out
        \item obiekty dalej ($Z > Z_c$) mają $\Delta < 0$ - \textbf{za ekranem} (depth-in)
    \end{itemize}
\end{enumerate}

Podsumowując: asymetryczny frustum \textbf{przesuwa Zero parallax plane (ZPP)} z~nieskończoności na skończoną głębokość $Z_c$. Dzięki temu scena może mieć obiekty zarówno \emph{przed} ekranem (pop-out) jak i~\emph{za} nim (depth-in) - co jest kluczowe dla naturalnego efektu 3D na wyświetlaczu lentykularnym.

\medskip
\textbf{Dlaczego asymetryczny, a~nie obrócony (toed-in)?} Metoda toed-in (zbieganie osi optycznych) uzyskuje zbieżność w~$Z_c$ przez \textbf{obrót} kamer do środka. Ale obrócone kamery powodują \textbf{zniekształcenia keystonowe} (trapezoidalne):

\begin{center}
\begin{tikzpicture}[scale=0.36, >=latex, font=\tiny]
    \node[font=\scriptsize\bfseries, green!60!black] at (-4, 5.5) {Off-axis};
    \draw[green!60!black, thick] (-6.5, 0) rectangle (-1.5, 5);
    \foreach \x in {-5.5, -4.5, -3.5, -2.5} {
        \draw[green!60!black] (\x, 0) -- (\x, 5);
    }
    % Linie horyzontalne
    \foreach \y in {1, 2, 3, 4} {
        \draw[green!60!black] (-6.5, \y) -- (-1.5, \y);
    }
    \node[green!60!black, font=\scriptsize] at (-4, -0.5) {linie r\'ownolegle};

    \node[font=\scriptsize\bfseries, red!70] at (4, 5.5) {Toed-in};
    \draw[red!70, thick] (1.5, 0) rectangle (6.5, 5);
    \draw[red!70] (2.3, 0) -- (2.0, 5);
    \draw[red!70] (3.3, 0) -- (3.2, 5);
    \draw[red!70] (4.3, 0) -- (4.4, 5);
    \draw[red!70] (5.3, 0) -- (5.6, 5);
    % linie po horoyzoncie still parallel
    \foreach \y in {1, 2, 3, 4} {
        \draw[red!70] (1.5, \y) -- (6.5, \y);
    }
    \node[red!70, font=\scriptsize] at (4, -0.5) {linie zbiegaj\k{a} si\k{e}!};
\end{tikzpicture}
\end{center}




Zamiast obracać kamerę (toe-in), przesuwamy granice frustumu na near plane o~wartość $\text{shift}_{\text{near}}$.
Ponieważ frustum to wiązka prostych wychodzących  kamery, przesunięcie na dowolnej głębokości~$z$ wynika z~podobieństwa trójkątów i~rośnie \textbf{liniowo}: na~$z = Z_c$ wynosi dokładnie~$D/2$, czyli wewnętrzne krawędzie obu frustumów spotykają się w~osi symetrii.

\begin{itemize}
    \item $w$ -- połowa szerokości near plane w~jednostkach świata (half-width),
    \item $\text{shift}_{\text{near}}$ -- przesunięcie frustumu na near plane ku~środkowi.
\end{itemize}


W~symetrycznym frustumie (bez konwergencji) granice near plane to $\text{left} = -w$, $\text{right} = +w$. Off-axis przesuwa te granice o~$\text{shift}_{\text{near}}$:

Dla \textbf{lewej kamery} (frustum przesunięty w~prawo, ku~środkowi):
\begin{align}
    \text{left}_L  &= -w + \text{shift}_{\text{near}} &
    \text{right}_L &= +w + \text{shift}_{\text{near}}
\end{align}

Dla \textbf{prawej kamery} (frustum przesunięty w~lewo):
\begin{align}
    \text{left}_R  &= -w - \text{shift}_{\text{near}} &
    \text{right}_R &= +w - \text{shift}_{\text{near}}
\end{align}

Granice \texttt{top}/\texttt{bottom} pozostają symetryczne (rozstaw kamer jest tylko w~osi $x$).


\subsection{Wyznaczanie wzoru z konwergencją}
\paragraph{Krok A: Projekcje bez konwergencji (powtórzenie).}
Z~sekcji~\ref{sec:stereo_projection} mamy:
\begin{align}
    x_{dl}^{(0)} &= \frac{s(X + D/2)}{Z} \quad\text{(lewa kamera)} \\[3pt]
    x_{dr}^{(0)} &= \frac{s(X - D/2)}{Z} \quad\text{(prawa kamera)}
\end{align}
Dysparyczność (różnica) wynosi $\Delta^{(0)} = sD/Z > 0$ - \textbf{zawsze} pop-out.

\paragraph{Krok B: Dodajemy przesunięcia $\delta_L$, $\delta_R$.}
Modyfikujemy projekcje o~\textbf{stałe} (niezależne od~$X$,~$Z$) przesunięcia:
\begin{align}
    x_{dl} &= \frac{s(X + D/2)}{Z} + \delta_L \label{eq:xdl_shifted}\\[3pt]
    x_{dr} &= \frac{s(X - D/2)}{Z} + \delta_R \label{eq:xdr_shifted}
\end{align}



\paragraph{Krok C: Warunek zerowej dysparyczności przy $Z = Z_c$.}
Żądamy, aby dysparyczność znikała dokładnie przy $Z = Z_c$:
\begin{equation}
    \Delta_c \big|_{Z=Z_c} = x_{dl}\big|_{Z=Z_c} - x_{dr}\big|_{Z=Z_c} = 0
\end{equation}

Podstawiamy (\ref{eq:xdl_shifted}) i~(\ref{eq:xdr_shifted}):
\begin{equation}
    \left[\frac{s(X + D/2)}{Z_c} + \delta_L\right] - \left[\frac{s(X - D/2)}{Z_c} + \delta_R\right] = 0
\end{equation}

Wyrazy z~$X$ skracają się ($sX/Z_c - sX/Z_c = 0$):
\begin{equation}
    \frac{sD}{Z_c} + \delta_L - \delta_R = 0
    \quad\Longrightarrow\quad
    \delta_R - \delta_L = \frac{sD}{Z_c}
    \label{eq:delta_condition}
\end{equation}

 jedno równanie , dwie niewiadome 

\paragraph{Krok D: Warunek symetrii (punkt środkowy bez zmian).}
Chcemy, żeby konwergencja zmieniała tylko \textbf{głębię} (dysparyczność), a~nie \textbf{kierunek boczny} (punkt środkowy). To wymaga:
\begin{equation}
    \frac{x_{dl} + x_{dr}}{2} = \frac{x_{dl}^{(0)} + x_{dr}^{(0)}}{2} = \frac{sX}{Z}
\end{equation}

Punkt środkowy z~przesunięciami:
\begin{equation}
    \frac{x_{dl} + x_{dr}}{2} = \frac{sX}{Z} + \frac{\delta_L + \delta_R}{2}
\end{equation}

Żeby punkt środkowy się nie zmienił:
\begin{equation}
    \delta_L + \delta_R = 0
    \quad\Longrightarrow\quad
    \delta_L = -\delta_R
    \label{eq:delta_symmetry}
\end{equation}

\paragraph{Krok E: Rozwiązanie układu równań.}
Z~(\ref{eq:delta_condition}) i~(\ref{eq:delta_symmetry}):
\begin{align}
    \delta_R - \delta_L &= \frac{sD}{Z_c} \\[2pt]
    \delta_R + \delta_L &= 0
\end{align}

Dodając oba równania: $2\delta_R = sD/Z_c$, zatem:
\begin{equation}
    \boxed{
    \delta_L = -\frac{sD}{2Z_c}, \qquad
    \delta_R = +\frac{sD}{2Z_c}
    }
    \label{eq:delta_solution}
\end{equation}

Interpretacja: lewa kamera przesuwa frustum w~\textbf{lewo} ($\delta_L < 0$), prawa w~\textbf{prawo} ($\delta_R > 0$) - obie ``patrzą do środka'', ale \textbf{bez obracania} osi optycznych.

\paragraph{Krok F: Ostateczne wzory projekcji z~konwergencją.}
Podstawiamy (\ref{eq:delta_solution}) do (\ref{eq:xdl_shifted})--(\ref{eq:xdr_shifted}):

\textbf{Lewa kamera} (off-axis):
\begin{equation}
    x_{dl} = \frac{s(X + D/2)}{Z} - \frac{sD}{2Z_c}
    \label{eq:xdl_conv}
\end{equation}

\textbf{Prawa kamera} (off-axis):
\begin{equation}
    x_{dr} = \frac{s(X - D/2)}{Z} + \frac{sD}{2Z_c}
    \label{eq:xdr_conv}
\end{equation}

\subsection{Dysparyczność z~konwergencją}

\begin{equation}
    \Delta_c = x_{dl} - x_{dr} = \frac{sD}{Z} - \frac{sD}{Z_c} = \frac{sD(Z_c - Z)}{Z \cdot Z_c}
    \label{eq:disparity_conv}
\end{equation}

Trzy przypadki:
\begin{itemize}
    \item $Z < Z_c$: $\Delta_c > 0$ - \textbf{przed ekranem} (pop-out)
    \item $Z = Z_c$: $\Delta_c = 0$ - \textbf{na ekranie} (zero parallax)
    \item $Z > Z_c$: $\Delta_c < 0$ - \textbf{za ekranem} (depth-in)
\end{itemize}

\textbf{Punkt środkowy} - przesunięcia off-axis się skracają:
\begin{equation}
    \frac{x_{dl} + x_{dr}}{2} = \frac{sX}{Z} \quad\text{(bez zmian!)}
    \label{eq:midpoint_conv}
\end{equation}

konwergencja zmienia tylko głębię

\subsection{Wyprowadzenie $M_{\text{SPconv}}$}

We wzorze~(\ref{eq:perceived_point}) wspólny mianownik miał postać $w = d + \Delta$, gdzie $\Delta = x_{dl} - x_{dr} = \frac{sD}{Z}$ to dysparyczność bez konwergencji~(\ref{eq:metric_disparity}):
\begin{equation}
    w = d + \Delta = d + \frac{sD}{Z}
    \quad\text{(bez konwergencji, } \text{)}
    \label{eq:w_no_conv}
\end{equation}

Podstawiamy nową dysparyczność~(\ref{eq:disparity_conv}) w~miejsce $\Delta$:
\begin{equation}
    w_c = d + \Delta_c = d + \frac{sD(Z_c - Z)}{Z Z_c} = \frac{dZZ_c + sD(Z_c - Z)}{ZZ_c}
    \label{eq:wc_def}
\end{equation}

 $Z_c \to \infty$, wyrażenie $\frac{Z_c - Z}{Z_c} \to 1$ i~$w_c \to w$ --- formuły się zgadzają.


\begin{equation}
    \frac{d}{w_c} = \frac{dZZ_c}{dZZ_c + sD(Z_c - Z)}
\end{equation}

Postrzegana głębokość:
\begin{align}
    z_t &= z_u\!\left(1 - \frac{d}{w_c}\right)
        = z_u \cdot \frac{w_c - d}{w_c}
        = z_u \cdot \frac{\Delta_c}{w_c} \notag\\[6pt]
    &= z_u \cdot \frac{\;\dfrac{sD(Z_c - Z)}{ZZ_c}\;}{\;\dfrac{dZZ_c + sD(Z_c - Z)}{ZZ_c}\;} \notag\\[6pt]
    &= z_u \cdot \frac{sD(Z_c - Z)}{dZZ_c + sD(Z_c - Z)}
    \label{eq:zt_conv}
\end{align}


\begin{align}
    x_t &= x_u + \frac{d}{w_c}\!\left(\frac{sX}{Z} - x_u\right) \notag\\[6pt]
    &= x_u\!\left(1 - \frac{d}{w_c}\right) + \frac{d \cdot sX}{Z \cdot w_c} \notag\\[6pt]
    &= x_u \cdot \frac{\Delta_c}{w_c} + \frac{dsX}{Z \cdot w_c}
    = \frac{x_u \cdot \Delta_c \cdot Z + dsX}{Z \cdot w_c} \notag\\[6pt]
    &= \frac{x_u \cdot \dfrac{sD(Z_c - Z)}{\cancel{ZZ_c}} \cdot Z + dsX}{\;Z \cdot \dfrac{dZZ_c + sD(Z_c - Z)}{\cancel{ZZ_c}}\;} \notag\\[6pt]
    &= \frac{sDx_u(Z_c - Z) + dsXZ_c}{dZZ_c + sD(Z_c - Z)}
    = \frac{s\big[dXZ_c + Dx_u(Z_c - Z)\big]}{dZZ_c + sD(Z_c - Z)}
    \label{eq:xt_conv}
\end{align}

Analogicznie:
\begin{equation}
    y_t = \frac{s\big[dYZ_c + Dy_u(Z_c - Z)\big]}{dZZ_c + sD(Z_c - Z)}
    \label{eq:yt_conv}
\end{equation}

\subsection{Macierz jednorodna $M_{\text{SPconv}}$ ($4\times 4$)}

Mianownik: $W_c = dZZ_c + sD(Z_c - Z)$.

 liczniki (iloczyn $W_c \cdot x_t$ itd) jako funkcje liniowe $(X, Y, Z, 1)$:
\begin{align}
    W_c \cdot x_t &= sdZ_c \cdot X + 0 \cdot Y - sDx_u \cdot Z + sDZ_c x_u \label{eq:num_x_conv}\\[2pt]
    W_c \cdot y_t &= 0 \cdot X + sdZ_c \cdot Y - sDy_u \cdot Z + sDZ_c y_u \label{eq:num_y_conv}\\[2pt]
    W_c \cdot z_t &= 0 \cdot X + 0 \cdot Y - sDz_u \cdot Z + sDz_u Z_c \label{eq:num_z_conv}\\[2pt]
    W_c &= 0 \cdot X + 0 \cdot Y + (dZ_c - sD) \cdot Z + sDZ_c \label{eq:num_w_conv}
\end{align}

Stąd:
\begin{equation}
    \boxed{
    M_{\text{SPconv}} = \begin{pmatrix}
        sdZ_c & 0 & -sDx_u & sDZ_c x_u \\[3pt]
        0 & sdZ_c & -sDy_u & sDZ_c y_u \\[3pt]
        0 & 0 & -sDz_u & sDz_u Z_c \\[3pt]
        0 & 0 & dZ_c - sD & sDZ_c
    \end{pmatrix}
    }
    \label{eq:M_conv}
\end{equation}

\textbf{Jako macierz jednorodna $4\times 4$:}
{\small
\begin{equation}
    \begin{pmatrix} x_t \\ y_t \\ z_t \\ 1 \end{pmatrix}
    = \frac{1}{W_c}
    \begin{pmatrix}
        sdZ_c & 0     & -sDx_u    & sDZ_c x_u \\
        0     & sdZ_c & -sDy_u    & sDZ_c y_u \\
        0     & 0     & -sDz_u    & sDz_u Z_c \\
        0     & 0     & dZ_c - sD & sDZ_c
    \end{pmatrix}
    \begin{pmatrix} X \\ Y \\ Z \\ 1 \end{pmatrix}
    \label{eq:M_conv_final}
\end{equation}
}

Mnożenie jest przemienne więc można użyć zapisu przyjemniejszego do liczenia MxM * skalar:

{\small
\begin{equation}
    \begin{pmatrix} x_t \\ y_t \\ z_t \\ 1 \end{pmatrix}
    =
    \begin{pmatrix}
        sdZ_c & 0     & -sDx_u    & sDZ_c x_u \\
        0     & sdZ_c & -sDy_u    & sDZ_c y_u \\
        0     & 0     & -sDz_u    & sDz_u Z_c \\
        0     & 0     & dZ_c - sD & sDZ_c
    \end{pmatrix}
    \begin{pmatrix} X \\ Y \\ Z \\ 1 \end{pmatrix}
    \cdot \frac{1}{W_c}
    \label{eq:M_conv_final}
\end{equation}
}


\begin{equation}
    W_c = (dZ_c - sD)\,Z + sDZ_c
\end{equation}

Po podziale jednorodnym ($\div W_c$) otrzymujemy $(x_t, y_t, z_t)$.

$M_{\text{SPconv}}$ oraz $M_{\text{SPconv}}^{-1}$ idealnie nadają się do zastosowania w~shaderach GPU: dla dowolnego punktu $(X,Y,Z,1)$ sprowadza się do jednego mnożenia macierz 4x4--wektor 4x1.

\input{appendix}

\end{document}

